## 2.8-Making-Microservices-more-resilient

In microservices architecture, the term resilient (or resilience) refers to a system's ability to withstand failures, recover quickly, and continue functioning correctly even when some of its components fail or face unexpected issues.

Because microservices are distributed systems, failures are inevitable‚Äînetwork issues, service crashes, slow responses, or resource exhaustion can happen. A resilient microservice ensures that these failures do not cascade and bring down the entire system.

![alt text](image-2.png)


![alt text](image-1.png)

![alt text](image-3.png)

### Improving service resiliency

* Asynchronous communication
* Retry with expoental backoff 
    * Automatically retry failed requests with exponential backoff.
* Circuit Breaker Pattern

### **What is Circuit Breaker Pattern?**

The Circuit Breaker Pattern is a **resilience pattern** in microservices that **stops repeatedly calling a failing service** and allows it **time to recover**.

Think of it **like an electric circuit breaker in your house**:

* When there‚Äôs a **problem (short circuit)** ‚Üí **Breaker trips (opens)** ‚Üí **Stops electricity flow** to protect the system.
* After some **time**, it **tries again** to see if the problem is fixed.

In microservices:

* If **Service A** keeps calling **Service B**, and B keeps **failing or is too slow**, the **circuit breaker ‚Äúopens‚Äù** and **stops requests** to B for a while.
* This **prevents overloading** B and **frees up A to handle other requests**.

#### **How It Works (3 States)**

1. **Closed (Normal)** 

   * Calls are working fine.
   * Service A ‚Üí Service B works normally.

2. **Open (Problem Detected)** 

   * Too many failures happen.
   * Circuit ‚Äúopens‚Äù and **stops sending requests** to B.
   * A can **fallback** instead (e.g., show cached data).

3. **Half-Open (Testing)** üîÑ

   * After some wait time, the breaker **allows a few test requests** to B.
   * If B responds successfully ‚Üí **Circuit closes (back to normal)**.
   * If B still fails ‚Üí **Circuit stays open** longer.

#### **Simple Real-World Example**

* **Order Service ‚Üí Payment Service**
* Payment Service is **down**.
* If we **keep calling it**, it will:

  1. Waste network resources
  2. Slow down Order Service
  3. Possibly **crash the whole app**

**With Circuit Breaker:**

* After 3 continuous payment failures ‚Üí **Breaker opens**.
* Order Service **stops calling Payment Service** for 30 seconds.
* It **marks orders as ‚ÄúPayment Pending‚Äù** instead (fallback).
* After 30 seconds ‚Üí It **sends one test request** to Payment Service.
* If success ‚Üí **Back to normal**.

#### **Benefits**

* **Prevents cascading failures**
* **Protects resources**
* **Gives time for failing service to recover**
* **Improves user experience** with fallbacks

### **What is Retry Pattern?**

The **Retry Pattern** is a **resilience pattern** where your service **automatically tries again** when a request to another service **fails due to a temporary problem**.

Think of it like **calling your friend on the phone**:

* If the **call doesn‚Äôt connect** (network issue),
* You **wait a little** and **try again**,
* Usually, the call works on the **second or third try**.

#### **How It Works**

1. Service A calls Service B.
2. If the **request fails** due to a **temporary issue** (like timeout, network glitch):

   * Service A **waits a bit**
   * Then **retries the request**
3. If it **succeeds**, all good.
4. If it **keeps failing after multiple retries**, you can **stop and fallback**.

#### **Important Things**

* **Don‚Äôt retry immediately** ‚Üí use **Exponential Backoff**:

  * 1st retry after 1 second
  * 2nd retry after 2 seconds
  * 3rd retry after 4 seconds
* **Don‚Äôt retry forever** ‚Üí Set a **max retry count**.
* Combine with **Circuit Breaker** to avoid overloading a failing service.

#### **Real-World Example**

Imagine **Order Service ‚Üí Payment Service**:

1. Payment Service is **temporarily slow** due to high traffic.
2. Order Service **calls Payment API** ‚Üí Timeout.
3. Retry Pattern says:

   * **Wait 1 second ‚Üí Retry**
   * If still fails ‚Üí **Wait 2 seconds ‚Üí Retry again**
   * If succeeds ‚Üí **Payment completed** ‚úÖ
   * If fails after 3 tries ‚Üí **Fallback to ‚ÄúPayment Pending‚Äù** ‚ùå

#### **Benefits**

* Handles **temporary failures automatically**
* Reduces **unnecessary errors to users**
* Works well with **transient network issues**


### **Common Problems Using HttpClient**

#### **1. Socket Exhaustion**

* If you **create a new `HttpClient` object for every request**, it **does not immediately release the TCP connection**.
* Each `HttpClient` instance **opens a new socket**.
* In high-traffic apps, this leads to:

  * **Too many open sockets**
  * **System.Net.Sockets.SocketException: Address already in use**
* This is called **socket exhaustion**.

**Example of bad usage:**

```csharp
public async Task<string> CallServiceAsync()
{
    using var client = new HttpClient(); // ‚ùå Creating per request
    return await client.GetStringAsync("https://example.com/api/data");
}
```

* Each call creates a **new socket**, which stays in **TIME\_WAIT** state after disposal.

#### **2. DNS Changes Are Ignored**

* Old `HttpClient` instances **cache DNS lookups**.
* If the **server IP changes** (like in **Kubernetes or cloud deployments**), your client **might still call the old IP**, causing failures.

#### **3. Performance Overhead**

* Continuously creating and disposing `HttpClient` objects is **expensive**.
* It **wastes memory and CPU** by repeatedly creating TCP connections instead of **reusing them**.

### **Correct Way to Use HttpClient**

#### **1. Use a Single Static HttpClient**

* Create **one `HttpClient` instance** and reuse it for the **entire app lifetime**.

```csharp
public class MyService
{
    private static readonly HttpClient _httpClient = new HttpClient(); // Reused

    public async Task<string> CallServiceAsync()
    {
        return await _httpClient.GetStringAsync("https://example.com/api/data");
    }
}
```

#### **2. Use HttpClientFactory**

* Introduced in **.NET Core 2.1** to **solve these problems**.
* Benefits:

  * **Manages connection pooling automatically**
  * **Avoids socket exhaustion**
  * **Supports DNS refresh**
  * **Easy to configure retries, circuit breakers with Polly**

**Example using `IHttpClientFactory`:**

```csharp
// Program.cs or Startup.cs
builder.Services.AddHttpClient("MyApiClient");

// Usage in service
public class MyService
{
    private readonly HttpClient _client;

    public MyService(IHttpClientFactory factory)
    {
        _client = factory.CreateClient("MyApiClient");
    }

    public async Task<string> CallServiceAsync()
    {
        return await _client.GetStringAsync("https://example.com/api/data");
    }
}
```

### **Summary of Problems**

1. **Socket exhaustion** ‚Äì too many short-lived connections
2. **DNS refresh issues** ‚Äì can fail in cloud/microservices
3. **Performance issues** ‚Äì creating/discarding `HttpClient` is expensive

**Solution** ‚Üí **Use `HttpClientFactory`** with **Polly** for retries, circuit breakers, and timeouts.
